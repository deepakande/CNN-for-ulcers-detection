{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4oKIMR_5bMD",
        "outputId": "5819cf25-74d3-43df-e92f-9afe37f1e06e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mzSCuc_K5rAf",
        "outputId": "a366171f-db31-44cc-d154-9ee73dd80ac8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/12\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 0.5291 - loss: 1.7126 - val_accuracy: 0.7143 - val_loss: 0.4782\n",
            "Epoch 2/12\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.7739 - loss: 0.4561 - val_accuracy: 0.8571 - val_loss: 0.2761\n",
            "Epoch 3/12\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 2s/step - accuracy: 0.8419 - loss: 0.3710 - val_accuracy: 0.8980 - val_loss: 0.2928\n",
            "Epoch 4/12\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.8953 - loss: 0.2485 - val_accuracy: 0.9796 - val_loss: 0.1767\n",
            "Epoch 5/12\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.9204 - loss: 0.1973 - val_accuracy: 0.9184 - val_loss: 0.1977\n",
            "Epoch 6/12\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 0.9543 - loss: 0.1310 - val_accuracy: 0.9184 - val_loss: 0.1495\n",
            "Epoch 7/12\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.9775 - loss: 0.0994 - val_accuracy: 0.9388 - val_loss: 0.1650\n",
            "Epoch 8/12\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 0.9973 - loss: 0.0712 - val_accuracy: 0.9388 - val_loss: 0.1269\n",
            "Epoch 9/12\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0557 - val_accuracy: 0.9388 - val_loss: 0.1558\n",
            "Epoch 10/12\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0425 - val_accuracy: 0.9388 - val_loss: 0.1292\n",
            "Epoch 11/12\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0336 - val_accuracy: 0.9388 - val_loss: 0.1519\n",
            "Epoch 12/12\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0267 - val_accuracy: 0.9388 - val_loss: 0.1335\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "# Define paths to the image folders\n",
        "healthy_folder = '/content/drive/My Drive/ALL/Endoscopic/antralulcer/Healthy Antral picture'\n",
        "unhealthy_folder = '/content/drive/My Drive/ALL/Endoscopic/antralulcer/Antral Ulcer(Unhealthy)'\n",
        "\n",
        "# Load and preprocess images\n",
        "def load_and_preprocess_images(image_paths, target_size=(224, 224)):\n",
        "    images = []\n",
        "    for path in image_paths:\n",
        "        img = load_img(path, target_size=target_size)\n",
        "        img_array = img_to_array(img)\n",
        "        img_array = preprocess_input(img_array)\n",
        "        images.append(img_array)\n",
        "    return np.array(images)\n",
        "\n",
        "healthy_images = [os.path.join(healthy_folder, img) for img in os.listdir(healthy_folder)]\n",
        "unhealthy_images = [os.path.join(unhealthy_folder, img) for img in os.listdir(unhealthy_folder)]\n",
        "\n",
        "# Combine images and labels\n",
        "all_images = healthy_images + unhealthy_images\n",
        "all_labels = [0] * len(healthy_images) + [1] * len(unhealthy_images)\n",
        "\n",
        "# Convert image paths to feature vectors\n",
        "X = load_and_preprocess_images(all_images)\n",
        "\n",
        "# Apply SMOTE to balance the classes\n",
        "smote = SMOTE(random_state=1)\n",
        "X_resampled, y_resampled = smote.fit_resample(X.reshape(-1, np.prod(X.shape[1:])), all_labels)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=1)\n",
        "\n",
        "# Convert labels to numpy arrays\n",
        "train_labels = np.array(train_labels)\n",
        "val_labels = np.array(val_labels)\n",
        "\n",
        "# Define MobileNetV2 base model\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Add custom head for binary classification\n",
        "model = Sequential([ base_model, GlobalAveragePooling2D(), Dense(512, activation='relu'), Dense(1, activation='sigmoid')])\n",
        "\n",
        "# Freeze base model layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Reshape the feature vectors to match the input shape expected by the MobileNetV2 model\n",
        "train_images = train_images.reshape(-1, 224, 224, 3)\n",
        "val_images = val_images.reshape(-1, 224, 224, 3)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_images, train_labels,\n",
        "    epochs=12,\n",
        "    validation_data=(val_images, val_labels)\n",
        ")\n",
        "\n",
        "# Save the trained model\n",
        "model.save('/content/drive/My Drive/ALL/Endoscopic/antralulcer/model_mobilenet_smote.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pc5yE8wV5gKS",
        "outputId": "d6719e79-9bab-4a16-ef1d-120f5908baf8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "Prediction: Unhealthy Antral\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array  # Add this import if not already present\n",
        "\n",
        "# Define a function to preprocess the input image and predict its class\n",
        "def predict_image(image_path):\n",
        "    model = tf.keras.models.load_model('/content/drive/My Drive/ALL/Endoscopic/antralulcer/model_mobilenet_smote.h5')\n",
        "    img = load_img(image_path, target_size=(224, 224))  # Use load_img directly\n",
        "    img_array = img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)  # Ensure you preprocess as during training\n",
        "    prediction = model.predict(img_array)\n",
        "    if prediction > 0.5:\n",
        "        return \"Unhealthy Antral\"\n",
        "    else:\n",
        "        return \"Healthy Antral\"\n",
        "\n",
        "# Example usage:\n",
        "image_path = '/content/9.JPG'  # Replace with the path to your image\n",
        "prediction = predict_image(image_path)\n",
        "print(\"Prediction:\", prediction)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}